{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71a0eb84",
   "metadata": {},
   "source": [
    "# records\n",
    "\n",
    "> Module fore records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dea993",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce05ce76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d183d8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "from enum import Enum, auto\n",
    "from typing import ClassVar, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265c5d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class TimeseriesRecording:\n",
    "    \"\"\"Base class for data that is oriented along an array representing time.\n",
    "\n",
    "    Subclasses of this add specific data types, such as PSG labels or triaxial accelerometer readings.\n",
    "    \"\"\"\n",
    "\n",
    "    time: npt.NDArray[np.float64]  # seconds\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.time = np.squeeze(self.time)\n",
    "        assert len(self.time.shape) == 1\n",
    "\n",
    "    def bin_based_on(self, time: np.ndarray):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def align_self_and_other_series(self, other: \"TimeseriesRecording\") -> None:\n",
    "        \"\"\"\n",
    "        MUTATING METHOD. Changes both `self` and `other` so that only the shared times are kept.\n",
    "\n",
    "        That is, when this method completes, both self.time and other.time contain only timestamps\n",
    "        common to the two objects before this method was called.\n",
    "        \"\"\"\n",
    "        start = max(self.time.min(), other.time.min())\n",
    "        end = min(self.time.max(), other.time.max())\n",
    "\n",
    "        self.trim(start, end)\n",
    "        other.trim(start, end)\n",
    "\n",
    "    def fill_gaps(self, max_gap_seconds: float, fill_dt: float):\n",
    "        gaps = self._identify_gaps(max_gap_seconds=max_gap_seconds)\n",
    "\n",
    "        if len(gaps) == 0:\n",
    "            return\n",
    "\n",
    "        fills = [np.arange(self.time[i], self.time[i + 1], fill_dt) for i in gaps]\n",
    "\n",
    "        self.time = fill_numpy(base_array=self.time, fills=fills, start_idx=gaps)\n",
    "\n",
    "        self._fill_gaps_specific_data(gaps, fills)\n",
    "\n",
    "    def sort_by_time(self) -> None:\n",
    "        sort_idx = np.argsort(self.time)\n",
    "        self._sort_specific_data(sort_idx)\n",
    "        self.time = self.time[sort_idx]\n",
    "\n",
    "    def _identify_gaps(self, max_gap_seconds: float) -> npt.NDArray[np.int64]:\n",
    "        \"\"\"Finds places where the time step between self.time indices exceeds the given maximum.\n",
    "\n",
    "        Parameters\n",
    "        ---\n",
    "        `max_gap_seconds`: `float`\n",
    "            If `np.diff(self.time)[i] > max_gap_seconds`, then `self.time[i]` is reported as a \"gap\" by including `i` in the returned array.\n",
    "\n",
    "        Returns\n",
    "        ---\n",
    "        Indices `i` of `self.time` such that `self.time[i+1] - self.time[i] > max_gap_seconds`.\n",
    "        \"\"\"\n",
    "        return np.flatnonzero(np.diff(self.time) > max_gap_seconds)\n",
    "\n",
    "    def _fill_gaps_specific_data(\n",
    "        self, gaps: npt.NDArray[np.int64], time_fillers: List[np.ndarray]\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Used by subclasses to fill their specific data. Arguments show indices where fillers were inserted and the time arrays that were inserted.\n",
    "\n",
    "        Parameters\n",
    "        ---\n",
    "        gaps: NumPy array of integers\n",
    "            Typically the output of self._identify_gaps. Indicates where in the time axis values were inserted (start indices).\n",
    "        time_fillers: List[np.ndarray]\n",
    "            The time arrays that were added. Subclasses might use this only to compute the length of the fillers to add, or might insert values that are a function of the times.\n",
    "        \"\"\"\n",
    "        return\n",
    "\n",
    "    def _sort_specific_data(self, sort_idx: npt.NDArray[np.int64]) -> None:\n",
    "        \"\"\"\n",
    "        Used in subclasses of TimeseriesRecording to sort type-specific data.\n",
    "\n",
    "        ** Mutating function **\n",
    "\n",
    "        Parameters:\n",
    "        ---\n",
    "        sort_idx: NumPy array of ints, usually the output of np.argsort on self.time\n",
    "            Subclasses should implement a version of this that handles re-organizing their specific data in the order given\n",
    "        \"\"\"\n",
    "        return\n",
    "\n",
    "    def _trim_specific_data(self, select_idx: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Used in subclasses of TimeseriesRecording to trim type-specific data based on an array of indices to include.\n",
    "\n",
    "        ** Mutating function **\n",
    "\n",
    "        Parameters:\n",
    "        ---\n",
    "        select_idx: NumPy array of ints or bools, usually the output of self._trim_time\n",
    "            Subclasses should implement a version of this that handles subsetting their specific data as specified using this array.\n",
    "            This method should support select_idx that provides indices to include OR booleans, one per element, indicating if should include.\n",
    "            E.g.: if our data is `np.array([1, 2, 3, 4])` then it should be equivalent to call this function with\n",
    "            `select_idx = np.array([1, 3])` or `select_idx = np.array([False, True, False, True])`\n",
    "        \"\"\"\n",
    "        return\n",
    "\n",
    "    def trim(self, start: float, end: float) -> None:\n",
    "        select_idx = self._trim_time(start, end)\n",
    "        self._trim_specific_data(select_idx)\n",
    "\n",
    "    def _trim_time(self, start: float, end: float) -> np.ndarray:\n",
    "        select = (start <= self.time) & (self.time <= end)\n",
    "        self.time = self.time[select]\n",
    "\n",
    "        return select\n",
    "\n",
    "@dataclass\n",
    "class AccelerometerRecord(TimeseriesRecording):\n",
    "    _xyz: np.ndarray\n",
    "    Hz: int | float | None = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        super().__post_init__()\n",
    "        assert self._xyz.shape == self._expected_xyz_shape\n",
    "\n",
    "    def bin_based_on(self, time: np.ndarray):\n",
    "        return\n",
    "\n",
    "    @property\n",
    "    def _expected_xyz_shape(self) -> Tuple[int, int]:\n",
    "        return (len(self.time), 3)\n",
    "\n",
    "    def _fill_gaps_specific_data(\n",
    "        self, gaps: npt.NDArray[np.int64], time_fillers: List[np.ndarray]\n",
    "    ):\n",
    "        zero_fills = [np.zeros((len(f), 3)) for f in time_fillers]\n",
    "        self._xyz = fill_numpy(self._xyz, fills=zero_fills, start_idx=gaps)\n",
    "\n",
    "    def resample(self, Hz: float):\n",
    "        self.sort_by_time()\n",
    "        new_time = np.arange(self.time[0], self.time[-1], 1 / Hz)\n",
    "\n",
    "        new_xyz = np.zeros((len(new_time), 3))\n",
    "\n",
    "        for j in range(3):\n",
    "            new_xyz[:, j] = np.interp(new_time, self.time, self.xyz[:, j])\n",
    "\n",
    "        self.time = new_time\n",
    "        self.xyz = new_xyz\n",
    "\n",
    "    @property\n",
    "    def x(self) -> np.ndarray:\n",
    "        return self._xyz[:, 0]\n",
    "\n",
    "    @x.setter\n",
    "    def x(self, value):\n",
    "        self._xyz[:, 0] = value\n",
    "\n",
    "    @property\n",
    "    def y(self) -> np.ndarray:\n",
    "        return self._xyz[:, 1]\n",
    "\n",
    "    @y.setter\n",
    "    def y(self, value):\n",
    "        self._xyz[:, 1] = value\n",
    "\n",
    "    @property\n",
    "    def z(self) -> np.ndarray:\n",
    "        return self._xyz[:, 2]\n",
    "\n",
    "    @z.setter\n",
    "    def z(self, value):\n",
    "        self._xyz[:, 2] = value\n",
    "\n",
    "    def trim(self, start: float, end: float) -> None:\n",
    "        select = self._trim_time(start, end)\n",
    "        self._xyz = self._xyz[select]\n",
    "\n",
    "    @property\n",
    "    def l2_norm(self) -> np.ndarray:\n",
    "        return np.sqrt(self.x * self.x + self.y * self.y + self.z * self.z)\n",
    "\n",
    "    @property\n",
    "    def xyz(self) -> np.ndarray:\n",
    "        return self._xyz\n",
    "\n",
    "    @xyz.setter\n",
    "    def xyz(self, value):\n",
    "        assert value.shape == self._expected_xyz_shape\n",
    "        self._xyz = value\n",
    "\n",
    "    @property\n",
    "    def txyz(self) -> np.ndarray:\n",
    "        stacked = np.vstack((self.time.T, self._xyz))\n",
    "        # stacked = np.vstack((self.time, self.x, self.y, self.z))\n",
    "        # stacked = stacked.T # shape (N, 4) instead of (4, N); N = len(self.x)\n",
    "        return stacked\n",
    "\n",
    "@dataclass\n",
    "class ActivityCountRecord(TimeseriesRecording):\n",
    "    count: np.ndarray\n",
    "\n",
    "    def _fill_gaps_specific_data(\n",
    "        self, gaps: npt.NDArray[np.int64], time_fillers: List[np.ndarray]\n",
    "    ):\n",
    "        self.count = fill_numpy(\n",
    "            self.count,\n",
    "            fills=[np.zeros_like(t) for t in time_fillers],  # fill with zeros like time\n",
    "            start_idx=gaps,\n",
    "        )\n",
    "\n",
    "    def bin_based_on(self, time: np.ndarray):\n",
    "        bins = compute_bins(self.time, time)\n",
    "        valid_bins = bins >= 0  # sometimes trim didn't work so well??\n",
    "        bins = bins[valid_bins]\n",
    "        weights = self.count[valid_bins]\n",
    "        binned = np.bincount(bins, weights=weights)\n",
    "        if len(time) != len(binned):\n",
    "            length = min(len(time), len(binned))\n",
    "            time = time[:length]\n",
    "            binned = binned[:length]\n",
    "\n",
    "        self.time = time\n",
    "        self.count = binned\n",
    "\n",
    "    def trim(self, start: float, end: float) -> None:\n",
    "        select = self._trim_time(start, end)\n",
    "        self.count = self.count[select]\n",
    "\n",
    "        \n",
    "class SleepOrWake(Enum):\n",
    "    \"\"\"\n",
    "    Very simple enum for fixing, once-and-for-all, meaning of class 0 and 1.\n",
    "    Use this enum when sensible for clarity in code.\n",
    "    \"\"\"\n",
    "\n",
    "    DO_NOT_USE = -2  # excluded post-hoc, e.g. padding\n",
    "    UNSCORED = -1\n",
    "    WAKE = 0\n",
    "    SLEEP = 1\n",
    "\n",
    "    \n",
    "class SleepStagesWLDR(Enum):\n",
    "    \"\"\"\n",
    "    Similar to SleepStages(Enum), but for Wake/Light/Deep/REM instead of Ns\n",
    "    \"\"\"\n",
    "\n",
    "    DO_NOT_USE = -2  # excluded post-hoc, e.g. padding\n",
    "    UNSCORED = -1\n",
    "    WAKE = 0\n",
    "    LIGHT = 1\n",
    "    DEEP = 2\n",
    "    REM = 3\n",
    "\n",
    "    def to_masked_sleep_wake(self) -> SleepOrWake:\n",
    "        match self:\n",
    "            case SleepStagesWLDR.DO_NOT_USE:\n",
    "                return SleepOrWake.DO_NOT_USE\n",
    "            case SleepStagesWLDR.UNSCORED:\n",
    "                return SleepOrWake.UNSCORED\n",
    "            case SleepStagesWLDR.WAKE:\n",
    "                return SleepOrWake.WAKE\n",
    "            case _:\n",
    "                return SleepOrWake.SLEEP\n",
    "    \n",
    "class SleepStages(Enum):\n",
    "    \"\"\"\n",
    "    Very simple enum for fixing, once-and-for-all, meaning of integer sleep stages.\n",
    "    Use this enum when possible for clarity in code.\n",
    "    \"\"\"\n",
    "\n",
    "    DO_NOT_USE = -2  # excluded post-hoc, e.g. padding\n",
    "    UNSCORED = -1\n",
    "    WAKE = 0\n",
    "    N1 = 1\n",
    "    N2 = 2\n",
    "    N3 = 3\n",
    "    N4 = 4\n",
    "    REM = 5\n",
    "\n",
    "    def to_masked_sleep_wake(self) -> SleepOrWake:\n",
    "        return self.to_WLDR().to_masked_sleep_wake()\n",
    "\n",
    "    def to_WLDR(self) -> SleepStagesWLDR:\n",
    "        match self:\n",
    "            case SleepStages.DO_NOT_USE:\n",
    "                return SleepOrWake.DO_NOT_USE\n",
    "            case SleepStages.UNSCORED:\n",
    "                return SleepStagesWLDR.UNSCORED\n",
    "            case SleepStages.WAKE:\n",
    "                return SleepStagesWLDR.WAKE\n",
    "            case SleepStages.N1 | SleepStages.N2:\n",
    "                return SleepStagesWLDR.LIGHT\n",
    "            case SleepStages.N3 | SleepStages.N4:\n",
    "                return SleepStagesWLDR.DEEP\n",
    "            case SleepStages.REM:\n",
    "                return SleepStagesWLDR.REM\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "PSG_Enums = SleepOrWake | SleepStagesWLDR | SleepStages\n",
    "\n",
    "\n",
    "class SleepClassificationProblem(Enum):\n",
    "    SLEEP_OR_WAKE = auto()\n",
    "    SLEEP_STAGES_WLDR = auto()\n",
    "    SLEEP_STAGES = auto()\n",
    "\n",
    "    def type_enum(self) -> PSG_Enums:\n",
    "        match self:\n",
    "            case SleepClassificationProblem.SLEEP_OR_WAKE:\n",
    "                return SleepOrWake\n",
    "            case SleepClassificationProblem.SLEEP_STAGES_WLDR:\n",
    "                return SleepStagesWLDR\n",
    "            case SleepClassificationProblem.SLEEP_STAGES:\n",
    "                return SleepStages\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PSGRecord(TimeseriesRecording):\n",
    "    psg: List[PSG_Enums]\n",
    "    label_type: ClassVar[PSG_Enums]\n",
    "\n",
    "    def __post_init__(self):\n",
    "        super().__post_init__()\n",
    "        assert len(self.psg) == len(self.time)\n",
    "\n",
    "    def _sort_specific_data(self, sort_idx: npt.NDArray[np.int64]) -> None:\n",
    "        self.psg = [self.psg[j] for j in sort_idx]\n",
    "\n",
    "    def _trim_specific_data(self, select_idx: np.ndarray) -> None:\n",
    "        if select_idx.dtype == bool:\n",
    "            # Reduce to case where indices to include are provided\n",
    "            select_idx = np.nonzero(select_idx)[0]\n",
    "        self.psg = [self.psg[j] for j in select_idx]\n",
    "\n",
    "    def _fill_gaps_specific_data(\n",
    "        self, gaps: npt.NDArray[np.int64], time_fillers: List[np.ndarray]\n",
    "    ):\n",
    "        for gap_idx, filler in zip(gaps, time_fillers):\n",
    "            fill_array = [self.label_type.UNSCORED] * len(filler)\n",
    "            self.psg = inserting_at_index(self.psg, fill_array, gap_idx + 1)\n",
    "\n",
    "    def bin_based_on(self, time: np.ndarray):\n",
    "        pass\n",
    "\n",
    "    def to_sleep_wake(\n",
    "        self,\n",
    "        unscored_as_wake: bool = True,\n",
    "    ) -> \"PSGSleepWakeRecord\":\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def labels(\n",
    "        self,\n",
    "        unscored_as_wake: bool = True,\n",
    "    ) -> np.ndarray:\n",
    "        # Make a transformation that either sends -1 to 0, or leaves as is.\n",
    "        def xfrm(x: int) -> int:\n",
    "            # xfrm = (lambda x: max(x, 0)) if unscored_as_wake else (lambda x: x)\n",
    "            if x == SleepOrWake.DO_NOT_USE.value:\n",
    "                return x\n",
    "            return max(x, 0) if unscored_as_wake else x\n",
    "\n",
    "        return np.array([xfrm(elt.value) for elt in self.psg], dtype=np.int64)\n",
    "\n",
    "    def sw_labels(\n",
    "        self,\n",
    "        unscored_as_wake: bool = True,\n",
    "    ) -> np.ndarray:\n",
    "        return self.to_sleep_wake().labels(unscored_as_wake=unscored_as_wake)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.psg)\n",
    "\n",
    "\n",
    "class PSGPredictionsShapeError(Exception):\n",
    "    def __init__(self, *args: object) -> None:\n",
    "        super().__init__(*args)\n",
    "\n",
    "\n",
    "class PSGPredictionsNotProbabilityVectorError(Exception):\n",
    "    def __init__(self, *args: object) -> None:\n",
    "        super().__init__(*args)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PSGModelOutputs(TimeseriesRecording):\n",
    "    \"\"\"\n",
    "    TimeseriesRecording output from models; models should indicate in their\n",
    "    implementation of evaluation which subclass of this is returned.\n",
    "\n",
    "    Probabilities should be a NumPy array shaped such that\n",
    "        self.probabilities[i]\n",
    "    indicates the probabilities of each sleep stage for times between\n",
    "        self.time[i] and self.time[i+1]\n",
    "    In particular, self.probabilities should have shape\n",
    "        (N,) or (N, m)\n",
    "    where N == len(self.time) and m = number of stages\n",
    "    \"\"\"\n",
    "\n",
    "    probabilities: np.ndarray\n",
    "\n",
    "    def __post_init__(self):\n",
    "        try:\n",
    "            assert len(self.time) == len(self.probabilities)\n",
    "        except AssertionError:\n",
    "            raise PSGPredictionsShapeError(\"len(probabilities) must equal len(time)\")\n",
    "\n",
    "        try:\n",
    "            # Do not require >=0, allows for masking\n",
    "            assert np.all(self.probabilities <= 1.0)\n",
    "        except AssertionError:\n",
    "            raise PSGPredictionsNotProbabilityVectorError(\n",
    "                \"Probabilities vector must contain entries between 0.0 and 1.0, inclusive.\"\n",
    "            )\n",
    "\n",
    "    def _sort_specific_data(self, sort_idx: npt.NDArray[np.int64]) -> None:\n",
    "        self.probabilities = self.probabilities[sort_idx]\n",
    "\n",
    "    def _trim_specific_data(self, select_idx: np.ndarray) -> None:\n",
    "        if select_idx.dtype == bool:\n",
    "            # Reduce to case where indices to include are provided\n",
    "            select_idx = np.nonzero(select_idx)\n",
    "        self.probabilities = self.probabilities[select_idx]\n",
    "\n",
    "\n",
    "class PSGSleepWakePredictions(PSGModelOutputs):\n",
    "    def __post_init__(self):\n",
    "        super().__post_init__()\n",
    "        try:\n",
    "            assert self.probabilities.shape == (len(self.time),)\n",
    "        except AssertionError:\n",
    "            raise PSGPredictionsShapeError(\"len(probabilities) must equal len(time)\")\n",
    "\n",
    "\n",
    "class PSGStagingPredictions(PSGModelOutputs):\n",
    "    n_stages: int\n",
    "\n",
    "    def __post_init__(self):\n",
    "        super().__post_init__()\n",
    "\n",
    "        try:\n",
    "            assert np.all(\n",
    "                (np.sum(self.probabilities, axis=-1) == 1.0)\n",
    "                | (np.min(self.probabilities, axis=-1) < 0.0)\n",
    "            )\n",
    "        except AssertionError:\n",
    "            problem_idx = np.nonzero(np.sum(self.probabilities, axis=-1) != 1.0)\n",
    "            return PSGPredictionsNotProbabilityVectorError(\n",
    "                \"Did not get a vector whose axis-0 arrays sum to 1.0\\n\"\n",
    "                + f\"Problems at indices:\\n{problem_idx}\"\n",
    "            )\n",
    "\n",
    "    def to_sleep_wake_predictions(self) -> PSGSleepWakePredictions:\n",
    "        return PSGSleepWakePredictions(\n",
    "            time=self.time,\n",
    "            probabilities=(1 - self.probabilities[:, 0]),  # P(sleep) = 1 - P(wake)\n",
    "        )\n",
    "\n",
    "    \n",
    "\n",
    "@dataclass\n",
    "class PSGSleepWakeRecord(PSGRecord):\n",
    "    label_type = SleepOrWake\n",
    "    psg: List[SleepOrWake]\n",
    "\n",
    "    def to_sleep_wake(self) -> \"PSGSleepWakeRecord\":\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def from_predictions(\n",
    "        predictions: PSGSleepWakePredictions, threshold: float = 0.5\n",
    "    ) -> \"PSGSleepWakeRecord\":\n",
    "        \"\"\"\n",
    "        Converts probabilistic outputs to definitive sleep-wake.\n",
    "        \"\"\"\n",
    "\n",
    "        def probas_to_class(p: float) -> SleepOrWake:\n",
    "            if p >= threshold:\n",
    "                return SleepOrWake.SLEEP\n",
    "            elif p >= 0:\n",
    "                return SleepOrWake.WAKE\n",
    "            elif p >= -1:\n",
    "                return SleepOrWake.UNSCORED\n",
    "            elif p < -1:\n",
    "                return SleepOrWake.DO_NOT_USE\n",
    "\n",
    "        binary_stages = [probas_to_class(p) for p in predictions.probabilities]\n",
    "\n",
    "        return PSGSleepWakeRecord(time=predictions.time, psg=binary_stages)\n",
    "\n",
    "    @classmethod\n",
    "    def from_staging_predictions(\n",
    "        cls, predictions: PSGStagingPredictions, threshold: float = 0.5\n",
    "    ) -> \"PSGSleepWakeRecord\":\n",
    "        return cls.from_predictions(\n",
    "            predictions.to_sleep_wake_predictions(), threshold=threshold\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.psg)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PSGStagingRecord(PSGRecord):\n",
    "    label_type = SleepStages\n",
    "    psg: List[SleepStages]\n",
    "\n",
    "    def __post_init__(self):\n",
    "        for j in range(len(self.psg)):\n",
    "            if self.psg[j] == SleepStages.N4:\n",
    "                self.psg[j] = SleepStages.N3\n",
    "\n",
    "    def to_sleep_wake(self) -> PSGSleepWakeRecord:\n",
    "        return PSGSleepWakeRecord(\n",
    "            time=self.time, psg=[p.to_masked_sleep_wake() for p in self.psg]\n",
    "        )\n",
    "\n",
    "    def to_WLDR(self) -> \"PSGStagingWLDRRecord\":\n",
    "        return PSGStagingWLDRRecord(\n",
    "            time=self.time,\n",
    "            psg=[p.to_WLDR() for p in self.psg],\n",
    "        )\n",
    "\n",
    "    def one_hot(self) -> np.ndarray:\n",
    "        return one_hot_encoded(self.labels(), n_classes=len(self.label_type))\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PSGStagingWLDRRecord(PSGRecord):\n",
    "    label_type = SleepStagesWLDR\n",
    "    psg: List[SleepStagesWLDR]\n",
    "\n",
    "    def to_sleep_wake(self) -> PSGSleepWakeRecord:\n",
    "        return PSGSleepWakeRecord(\n",
    "            time=self.time, psg=[p.to_masked_sleep_wake() for p in self.psg]\n",
    "        )\n",
    "\n",
    "    def to_WLDR(self) -> \"PSGStagingWLDRRecord\":\n",
    "        return self\n",
    "\n",
    "    def one_hot(self, unscored_as_wake: bool = False) -> np.ndarray:\n",
    "        return one_hot_encoded(\n",
    "            self.labels(unscored_as_wake=unscored_as_wake),\n",
    "            n_classes=len(self.label_type),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ef3899",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5413f6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pisces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de528a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package pisces:\n",
      "\n",
      "NAME\n",
      "    pisces\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _modidx\n",
      "    coooooore\n",
      "    core\n",
      "    load\n",
      "    records\n",
      "    records2\n",
      "\n",
      "VERSION\n",
      "    0.0.1\n",
      "\n",
      "FILE\n",
      "    /Users/ojwalch/Documents/pisces/pisces/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pisces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28affcaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
